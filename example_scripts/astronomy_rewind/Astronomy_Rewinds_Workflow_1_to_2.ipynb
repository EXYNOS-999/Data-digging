{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shouldn't turn on workflows 2a, 2b, and 2c until this workflow 1 final subject set is complete. \n",
    "\n",
    "Here is a list of steps that need to be carried out in order to be ready to activate workflows 2a, 2b, and 2c. \n",
    "\n",
    "-  Determine the final, aggregated consensus results for the subjects (the journal pages) that have been processed through workflow 1. \n",
    "\n",
    "-  Use these consensus results to create 3 new subject sets: \n",
    "\n",
    "   - subject set 1) images that should be associated w/ workflow 2a -- i.e., pages with just 1 single sky figure with axes labeled\n",
    "\n",
    "   - subject set 2) images that should be associated w/ workflow 2b -- i.e., pages with multiple sky figures with axes labeled\n",
    "\n",
    "   - subject set 3) images that should be associated w/ workflow 2c -- i.e., pages with sky figures without axes labeled\n",
    "\n",
    "Once you have access to the Project Editor for Astronomy Rewind, you can click on 'Workflows' to see workflows 2a, 2b, and 2c are. Once you go into the editor for each workflow, you can click on 'Test this workflow' to see what the volunteer experience will be in answering the tasks/questions for that workflow.\n",
    "\n",
    "Note: with this many images, it's best to use one of our API clients to automate the upload of subjects into a new subject set. See https://github.com/zooniverse/panoptes-python-client or https://github.com/zooniverse/panoptes-cli\n",
    "\n",
    "- Associate the new subject sets with their respective workflow (under 'associated subject set' in the project editor for that workflow). Also de-associate the current 'test images' subject sets that are just used for testing. \n",
    "\n",
    "- Once the subject sets are associated, have Alyssa, Julie and Gretchen review each workflow to make sure all the help context, text, etc. is correct and to make sure that the experience into WWT is still working properly. \n",
    "\n",
    "- Once workflow 1 is finished, go to the 'Visibility' tab and make Workflows 2a, 2b, and 2c active. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JSONParser(data):\n",
    "    \"\"\"call json.loads\"\"\"\n",
    "    return json.loads(data)\n",
    "\n",
    "\n",
    "def load_classifications(filename, json_columns=None):\n",
    "    \"\"\"\n",
    "    Load classifications into pandas dataframe.\n",
    "    \n",
    "    Some columns of the csv are embedded json and need special parsing.\n",
    "    \"\"\"\n",
    "    json_columns = json_columns or ['metadata', 'annotations', 'subject_data']\n",
    "    converters = {i: JSONParser for i in json_columns}\n",
    "\n",
    "    return pd.read_csv(filename, converters=converters)\n",
    "\n",
    "\n",
    "def unpack(series):\n",
    "    \"\"\"\n",
    "    Return the first value in a series.\n",
    "\n",
    "    All annotations values are lists because of a few multiple tasks.\n",
    "    The second multiple task always has the value of 'None of the above'\n",
    "    (For this dataset!)\n",
    "    \"\"\"\n",
    "    return [a[0] for a in series]\n",
    "\n",
    "\n",
    "def parse_classifications(filename):\n",
    "    \"\"\"\n",
    "    Load classifications and datamunge annotations column.\n",
    "    \"\"\"\n",
    "    data = load_classifications(filename)\n",
    "\n",
    "    # Only need the first item in the annotations list of json objects\n",
    "    data['annotations'] = unpack(data['annotations'])\n",
    "    return data\n",
    "\n",
    "\n",
    "def explore(data):\n",
    "    \"\"\" \n",
    "    print the values are in the annotations\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    values = np.unique(np.concatenate([a['value'] for a in data['annotations']]))\n",
    "    print(values)\n",
    "    return\n",
    "\n",
    "\n",
    "def write_workflow_csvs(filename, w2s=None, overwrite=False):\n",
    "    \"\"\"\n",
    "    Cull classifications file and write to new workflows.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        input csv file\n",
    "    \n",
    "    ws2 : dict\n",
    "        key: workflow title (for file naming)\n",
    "        value: Single string to select on within annotations values.\n",
    "    \n",
    "    overwrite : bool [False]\n",
    "        overwrite with new file \n",
    "    \"\"\"\n",
    "    # load and munge data\n",
    "    data = parse_classifications(filename)\n",
    "    \n",
    "    if w2s is None:\n",
    "        w2s = {'2a': 'A single sky\\xa0figure *with* axes labeled',\n",
    "               '2b': 'Two or more sky figures *with* axes labeled',\n",
    "               '2c': 'Sky figure(s) *without* axes labeled'}\n",
    "\n",
    "    for wf in w2s.keys():\n",
    "        # new filename assumes wf1 is in the first filename!\n",
    "        outname = filename.replace('wf1', 'wf{0:s}'.format(wf))\n",
    "        \n",
    "        # Identifiy matches to next workflow\n",
    "        iwf = [w2s[wf] in a['value'] for a in data['annotations']]\n",
    "\n",
    "        # create sub-copy of dataframe with only workflow matches\n",
    "        df = data.iloc[iwf]\n",
    "\n",
    "        # write ... or not\n",
    "        if not os.path.isfile(outname) or overwrite:\n",
    "            df.to_csv(outname)\n",
    "            msg = 'wrote'\n",
    "        else:\n",
    "            msg = 'not overwriting'\n",
    "        print('{0:s} {1:s}'.format(msg, outname))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote astronomy-rewind-classifications_wf2c.csv\n",
      "wrote astronomy-rewind-classifications_wf2a.csv\n",
      "wrote astronomy-rewind-classifications_wf2b.csv\n"
     ]
    }
   ],
   "source": [
    "# Slice out all other workflows and testing (and maintain the header line)\n",
    "! head -1 astronomy-rewind-classifications.csv > astronomy-rewind-classifications_wf1.csv \n",
    "! grep \"Workflow 1: Identifying figure types\" astronomy-rewind-classifications.csv >> astronomy-rewind-classifications_wf1.csv \n",
    "\n",
    "write_workflow_csvs('astronomy-rewind-classifications_wf1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
